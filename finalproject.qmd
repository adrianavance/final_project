---
  title: "Final Project"
author: "Jane Finocharo, Adriana Vance, and Ruining Zheng"
format: html
editor: visual
---
  
```{r}
library(tidyverse)
library(here)
library(readxl)
library(tidyr)
library(lubridate)
library(DescTools)
```

### Loading, Cleaning and Merging Datasets

We might want to find an easier way to load in the data, but for now I just created a data folder in my directory, and named the files CHR.csv, FEA.csv, FEA_supplement.csv, and snap.xlsx

How to access the data:
  
  \- **County Health Rankings**: At [this link](https://www.countyhealthrankings.org/health-data/methodology-and-sources/data-documentation), click "2024 CHR CSV Analytic Data". Rename file "CHR.csv"

\- **Food Environment Atlas**: At [this link](https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/#Current%20Version), click "Food Environemnt Atlas .csv Files." Open the .zip file, move "StateAndCountyData.csv" into data folder, rename "FEA.csv". Move "SupplementalDataCounty.csv" into data folder, rename "FEA_supplement.csv". Move "VariableList.csv" into the data folder.
                                                
\- **SNAP Policy Data:** At [this link](https://www.ers.usda.gov/data-products/snap-policy-data-sets/), click "Snap Policy Database." Move into data folder, rename "snap.xlsx"
                                              
```{r}
                                              
# county health rankings
chr_col_names <- names(read_csv(here("data", "CHR.csv"), n_max = 0))
county_health_rankings <- read_csv(here("data", "CHR.csv"), col_names = chr_col_names, skip = 2)

# food atlas + food atlas supplement
food_atlas <- read_csv(here("data", "FEA.csv"))
food_atlas_supplement <- read_csv(here("data", "FEA_supplement.csv"))
atlas_vars <- read_csv(here("data", "VariableList.csv"))

# SNAP policy data
snap <- read_excel(here("data", "snap.xlsx"), sheet = 2)

```
                                              
The county health rankings dataset has over 700 variables. We need to pick which ones we'd like to take as health measures of our counties. The other problem is understanding which years these datapoints come from, because it seems to differ by measure. Variables from county health rankings data that may be helpful:

-   v133_rawvalue, v133_numerator, v133_denominator (food environment index)
-   v132_rawvalue, v132_numerator, v132_denominator (access to exercise opportunities)
-   v132_rawvalue, v132_numerator, v132_denominator (income inequality)
-   v024_rawvalue, v024_numerator, v024_denominator (children in poverty)
-   v125_rawvalue, v125_numerator, v125_denominator (air pollution particulate matter)
-   v147_rawvalue, v147_numerator, v147_denominator (life expectancy)
-   v139_rawvalue, v139_numerator (food insecurity)
-   v083_rawvalue, v083_numerator, v083_denominator (ltd. access to healthy foods)
-   v003_rawvalue, v003_numerator, v003_denominator (uninsured adults)
-   v003_rawvalue, v003_numerator, v003_denominator (uninsured children)
-   v021_rawvalue, v021_numerator, v021_denominator (HS graduation)
-   v171_rawvalue (childcare cost burdened)
-   v156_rawvalue (traffic volume)
-   v058_rawvalue, v058_numerator, v058_denominator (rural)

The food environment atlas has various variables measuring access to food and other things, but the data is not tidy. Needs to be reorganized. The supplement contains population estimates. May be helpful as controls? - Might be helpful to select which food atlas variables we want to keep before tidying the data. That way we can filter beforehand.

The SNAP policy dataset is tidy and organized by state. Easy to interpret, but the observations are by yearmonth, meaning there are 12 observations for every year of the data. Not sure how to navigate this.

Challenges/to do: Clean datasets, understand what year all the variables come from, see if it is possible to merge datasets by county and understand which counties have changed overtime. [This link](https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html#list-tab-957819518) could be helpful for knowing which county boundaries have changed overtime.

### Tidying the Datasets for Merging

1.  Each variable must form a column
2.  Each observation must form a row
3.  Each type of observational unit forms a dataframe.

#### Food Atlas Dataframe

```{r}

# Changing values from scientific notation, and rounding decimals to be shorter
food_atlas <- food_atlas %>%
  mutate(Value = format(Value, scientific = FALSE)) %>%
  mutate(Value = map_dbl(food_atlas$Value, round, digits = 4))

# Pivoting dataset to tidy - variables as columns and counties as rows 

atlas_test <- food_atlas %>%
  pivot_wider(id_cols  = c(FIPS), # ID col is FIPS because of identical county names
              names_from = c(Variable_Code), 
              values_from = Value) %>%
  filter(FIPS > 1000) 

# There are two more variables than counties. The two observations here have NA values for all variables so will be filtered from the data
atlas_test %>%
  filter(is.na(atlas_test$LACCESS_POP10))

#Filtering here
atlas_test <- atlas_test %>%
  filter(FIPS != 2158 & FIPS != 46102)

# Create a tibble with unique state-county FIPS combos 
strings <- c("County", "Total", "Parish", "city", "Borough", "Census Area", "Municipality")
fips_distinct <- food_atlas %>%
  group_by(FIPS) %>%
  select(State, County, FIPS) %>%
  distinct() %>%
  filter(!str_detect(County, pattern = paste(strings, collapse = "|")))

# Bind dataframes with data and county/state names

food_atlas <- full_join(fips_distinct, atlas_test)

```

Here, we pivoted the data to be wider such that each unique county name formed a row. To do so, we used the FIPS codes which are unique identifiers of each county. After pivoting, we noticed there were state-level variables and duplicates of each county. We filtered out any county duplicates using stringr, and created a dataframe of unique state, county, and FIPS codes to join with the final dataset. The final dataset has 3,143 unique observations, which is the number of counties in the U.S.

#### SNAP Dataframe

```{r}

# Round the decimals to be the same pattern as above
snap <- snap %>%
  mutate_if(is.numeric, ~ round(., digits = 4)) %>%
  filter(yearmonth >= 201001) %>% # Only keep the data after year 2010. to assure that our analysis is closely connected to the current policies and circumstances.
  mutate(yearmonth = ym(yearmonth)) %>%
  mutate(year = year(yearmonth)) # Since the CHR data only contains year data, we also mutate a new column for year in SNAP. 

# Many rows have a large proportion of missing data, which add noise to the data. 
snap_na <- snap %>%
  mutate(na_count = rowSums(is.na(.))) %>%
  filter(na_count < 20) # We filter out rows with too many NA values (more than half of the variables except identifying variables)

snap_natest <- snap %>%
  select(-transben, -call_any, -faceini, -facerec, -(starts_with("cert"))) %>%
  na.omit()

rename_columns <- function(date, yearname){

  snap_date <- snap_natest %>%
  group_by(state_pc, year) %>%
  summarize_all(list(avg = Mode())) %>%
  select(-state_fips_avg, -statename_avg, -yearmonth_avg) %>%
  filter(year == date) 

  
names_date <- names(snap_date)
new_date <- paste(names_date, yearname, sep = "")
names(snap_date) <- new_date

return(snap_date)
}

rename_columns <- function(date, yearname){
  snap_date <- snap_natest %>%
    filter(year == date) %>%
    group_by(state_pc, year) %>%
    summarize_all(list(mode = ~Mode(.))) %>%
    select(-state_fips_mode, -statename_mode, -yearmonth_mode) %>%
    distinct(state_pc, .keep_all = TRUE)  # Keep only one row per state_pc

  names_date <- names(snap_date)
  new_date <- paste(names_date, yearname, sep = "")
  names(snap_date) <- new_date

  return(snap_date)
}
snap_2010 <- rename_columns(date = 2010, yearname = "_2010")
snap_2011 <- rename_columns(date = 2011, yearname = "_2011")
snap_2012 <- rename_columns(date = 2012, yearname = "_2012")
snap_2013 <- rename_columns(date = 2013, yearname = "_2013")
snap_2014 <- rename_columns(date = 2014, yearname = "_2014")
snap_2015 <- rename_columns(date = 2015, yearname = "_2015")
snap_2016 <- rename_columns(date = 2016, yearname = "_2016")
snap_2017 <- rename_columns(date = 2017, yearname = "_2017")
snap_2018 <- rename_columns(date = 2018, yearname = "_2018")
snap_2019 <- rename_columns(date = 2019, yearname = "_2019")
snap_2020 <- rename_columns(date = 2020, yearname = "_2020")

snap_year <- bind_cols(snap_2010, 
                       snap_2011, 
                       snap_2012, 
                       snap_2013, 
                       snap_2014, 
                       snap_2015, 
                       snap_2016, 
                       snap_2017, 
                       snap_2018, 
                       snap_2019, 
                       snap_2020) %>%
  rename(state = state_pc_2010) %>%
  group_by(state) %>%
  select(-starts_with("state_pc"), 
         -starts_with("year"))

```

The SNAP dataframe is a state-level dataframe of monthly reported data of SNAP policy relevant information by each state from 1996 to 2019. It supposed to have 51*12*10 = 6120 observations, but since we filter out data before year 2010 as well as states' data with too many missing values, the actual observation number is smaller.

Through looking at the documentation for the SNAP policy data, we learned that some variables were systematically missing. There were a few variables (transben, call_any, faceini, facerec, and the recertification variables) that had missing data for multiple years. Because the variables were missing not at random, we decided to remove them from our analysis. The rest of the variables were missing data from 2020, which is likely due to lack of data collection during the pandemic. NA observations were removed because imputation would likely not be able to reflect policy changes made during the pandemic. 

After dealing with the missing values, we grouped the dataset by year and state, and took the mode of each observation. The data was categorical, so mode was used to capture the most frequent instance of each policy during each year. 

#### County Health Rankings


```{r}

glimpse(county_health_rankings)

# selecting and renaming key variables. adding _chr at end so we know which variables came from CHR in merged dataset

chr_small <- 
  county_health_rankings |> 
  select(state_fips = 'State FIPS Code',
         county_fips = 'County FIPS Code',
         state = 'State Abbreviation',
         fips_5_digit = '5-digit FIPS Code',
         county = 'Name',
         food_env_index_chr = 'Food Environment Index raw value',
         exercise_access_chr = 'Access to Exercise Opportunities raw value',
         child_poverty_chr = 'Children in Poverty raw value',
         income_inequality_chr = 'Income Inequality raw value',
         air_pollution_chr = 'Air Pollution - Particulate Matter raw value',
         limited_healthy_food_chr = 'Limited Access to Healthy Foods raw value',
         uninsured_adults_chr = 'Uninsured Adults raw value',
         uninsured_children_chr = 'Uninsured Children raw value',
         childcare_cost_burden_chr = 'Child Care Cost Burden raw value',
         traffic_volume_chr = 'Traffic Volume raw value',
         rural_chr = '% Rural raw value', 
         hs_grad_rate_chr = 'High School Graduation raw value',
         food_insecurity_chr = 'Food Insecurity raw value',
         life_expectancy_chr = 'Life Expectancy raw value') |> 
  filter(county_fips!="000") |> 
  mutate(
    fips = as.numeric(fips_5_digit)) |> 
  select(!c(state_fips, county_fips, fips_5_digit)) |> 
  mutate_if(is.numeric, ~ round(., digits = 4))


```


### Merging Data

```{r}

# merging atlas and CHR
food_atlas <- food_atlas %>%
  rename(fips = FIPS)

anti_join(food_atlas, chr_small, by = "fips")
anti_join(chr_small, food_atlas)

```
The anti joins above show the counties in each dataset that are not represented in the other. All of these counties were either changed or deleted in the time that these data were collected. In order to be able to merge our datasets, we will remove these counties from the data. 

```{r}

food_atlas <- food_atlas %>%
  filter(fips != 2261, 
         fips != 2270, 
         fips != 46113, 
         fips != 51515)
chr_small <- chr_small %>%
  filter(fips != 2063,
         fips != 2066, 
         fips != 2158, 
         fips != 46102)

# Checking that there are no other unmatched observations 
anti_join(food_atlas, chr_small, by = "fips") # success!
anti_join(chr_small, food_atlas, by = "fips") # success!

atlas_chr <- full_join(food_atlas, chr_small, by = "fips") 

snap_year <- snap_year %>%
  rename(State = state)

atlas_chr_snap <- left_join(atlas_chr, snap_year)

```