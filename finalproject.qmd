---
title: "Final Project"
author: "Jane Finocharo, Adriana Vance, and Ruining Zheng"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(here)
library(readxl)
library(tidyr)
library(lubridate)

```

### Loading, Cleaning and Merging Datasets

We might want to find an easier way to load in the data, but for now I just created a data folder in my directory, and named the files CHR.csv, FEA.csv, FEA_supplement.csv, and snap.xlsx

How to access the data:

\- **County Health Rankings**: At [this link](https://www.countyhealthrankings.org/health-data/methodology-and-sources/data-documentation), click "2024 CHR CSV Analytic Data". Rename file "CHR.csv"

\- **Food Environment Atlas**: At [this link](https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/#Current%20Version), click "Food Environemnt Atlas .csv Files." Open the .zip file, move "StateAndCountyData.csv" into data folder, rename "FEA.csv". Move "SupplementalDataCounty.csv" into data folder, rename "FEA_supplement.csv". Move "VariableList.csv" into the data folder.

\- **Food Environment Atlas**: At [this link](https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/#Current%20Version), click "Food Environemnt Atlas .csv Files." Open the .zip file, move "StateAndCountyData.csv" into data folder, rename "FEA.csv". Move "SupplementalDataCounty.csv" into data folder, rename "FEA_supplement.csv".

\- **SNAP Policy Data:** At [this link](https://www.ers.usda.gov/data-products/snap-policy-data-sets/), click "Snap Policy Database." Move into data folder, rename "snap.xlsx"

```{r}
county_health_rankings <- read_csv(here("data", "CHR.csv"), col_names = TRUE)
food_atlas <- read_csv(here("data", "FEA.csv"))
food_atlas_supplement <- read_csv(here("data", "FEA_supplement.csv"))
atlas_vars <- read_csv(here("data", "VariableList.csv"))
snap <- read_excel(here("data", "snap.xlsx"), sheet = 2)

```

The county health rankings dataset has over 700 variables. We need to pick which ones we'd like to take as health measures of our counties. The other problem is understanding which years these datapoints come from, because it seems to differ by measure. Variables from county health rankings data that may be helpful:

-   v133_rawvalue, v133_numerator, v133_denominator (food environment index)
-   v132_rawvalue, v132_numerator, v132_denominator (access to exercise opportunities)
-   v132_rawvalue, v132_numerator, v132_denominator (income inequality)
-   v024_rawvalue, v024_numerator, v024_denominator (children in poverty)
-   v125_rawvalue, v125_numerator, v125_denominator (air pollution particulate matter)
-   v147_rawvalue, v147_numerator, v147_denominator (life expectancy)
-   v139_rawvalue, v139_numerator (food insecurity)
-   v083_rawvalue, v083_numerator, v083_denominator (ltd. access to healthy foods)
-   v003_rawvalue, v003_numerator, v003_denominator (uninsured adults)
-   v003_rawvalue, v003_numerator, v003_denominator (uninsured children)
-   v021_rawvalue, v021_numerator, v021_denominator (HS graduation)
-   v171_rawvalue (childcare cost burdened)
-   v156_rawvalue (traffic volume)
-   v058_rawvalue, v058_numerator, v058_denominator (rural)

The food environment atlas has various variables measuring access to food and other things, but the data is not tidy. Needs to be reorganized. The supplement contains population estimates. May be helpful as controls? - Might be helpful to select which food atlas variables we want to keep before tidying the data. That way we can filter beforehand.

The SNAP policy dataset is tidy and organized by state. Easy to interpret, but the observations are by yearmonth, meaning there are 12 observations for every year of the data. Not sure how to navigate this.

Challenges/to do: Clean datasets, understand what year all the variables come from, see if it is possible to merge datasets by county and understand which counties have changed overtime. [This link](https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html#list-tab-957819518) could be helpful for knowing which county boundaries have changed overtime.

### Tidying the Datasets for Merging

1.  Each variable must form a column
2.  Each observation must form a row
3.  Each type of observational unit forms a dataframe.

#### Food Atlas Dataframe

```{r}

# Changing values from scientific notation, and rounding decimals to be shorter
food_atlas <- food_atlas %>%
  mutate(Value = format(Value, scientific = FALSE)) %>%
  mutate(Value = map_dbl(food_atlas$Value, round, digits = 4))

# Pivoting dataset to tidy - variables as columns and counties as rows 

atlas_test <- food_atlas %>%
  pivot_wider(id_cols  = c(FIPS), # ID col is FIPS because of identical county names
              names_from = c(Variable_Code), 
              values_from = Value) %>%
  filter(FIPS > 1000) 

# There are two more variables than counties. The two observations here have NA values for all variables so will be filtered from the data
atlas_test %>%
  filter(is.na(atlas_test$LACCESS_POP10))

#Filtering here
atlas_test <- atlas_test %>%
  filter(FIPS != 2158 & FIPS != 46102)

# Create a tibble with unique state-county FIPS combos 
strings <- c("County", "Total", "Parish", "city", "Borough", "Census Area", "Municipality")
fips_distinct <- food_atlas %>%
  group_by(FIPS) %>%
  select(State, County, FIPS) %>%
  distinct() %>%
  filter(!str_detect(County, pattern = paste(strings, collapse = "|")))

# Bind dataframes with data and county/state names

food_atlas <- full_join(fips_distinct, atlas_test)

```

Here, we pivoted the data to be wider such that each unique county name formed a row. To do so, we used the FIPS codes which are unique identifiers of each county. After pivoting, we noticed there were state-level variables and duplicates of each county. We filtered out any county duplicates using stringr, and created a dataframe of unique state, county, and FIPS codes to join with the final dataset. The final dataset has 3,143 unique observations, which is the number of counties in the U.S.

#### SNAP Dataframe
```{r}

# Round the decimals to be the same pattern as above
snap <- snap %>%
  mutate_if(is.numeric, ~ round(., digits = 4)) %>%
  filter(yearmonth >= 201001) %>% # Only keep the data after year 2010. to assure that our analysis is closely connected to the current policies and circumstances.
  mutate(yearmonth = ym(yearmonth)) %>%
  mutate(year = year(yearmonth)) # Since the CHR data only contains year data, we also mutate a new column for year in SNAP. 

# Many rows have a large proportion of missing data, which add noise to the data. 
snap_na <- snap %>%
  mutate(na_count = rowSums(is.na(.))) %>%
  filter(na_count < 20) # We filter out rows with too many NA values (more than half of the variables except identifying variables)

```

The SNAP dataframeis a state-level dataframe of monthly reported data of SNAP policy relevant information by each state from 1996 to 2019. It supposed to have 51*12*10 = 6120 observations, but since we filter out data before year 2010 as well as states' data with too many missing values, the actual observation number is smaller.